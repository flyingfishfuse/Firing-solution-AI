C:\Stuff\cmdr
λ f:

F:\
λ cd "important code\workzone\

F:\important code\workzone
λ py -3.6
Python 3.6.6 (v3.6.6:4cf1f54eb7, Jun 27 2018, 03:37:03) [MSC v.1900 64 bit (AMD64)] on win32
Type "help", "copyright", "credits" or "license" for more information.
>>> from __future__ import absolute_import, division, print_function, unicode_literals
>>>
>>> import os
>>>
>>> import tensorflow as tf
2019-12-02 02:18:51.013816: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
>>> from tensorflow import keras
>>> from tensorflow.compat.v1 import ConfigProto
>>> from tensorflow.python.client import device_lib
>>> import colorama
>>> from colorama import Fore, Back, Style
>>> from timeit import default_timer as timer
>>>
>>> colorama.init()
>>>
>>> #gotta be the same
... os.environ["CUDA_VISIBLE_DEVICES"]="0"
>>> GPU_NUM                            = '/GPU:0'
>>> GPU_DESIGNATION                    = 0
>>> ALLOW_MEMORY_GROWTH                = True
>>> GPU_MEMORY_LIMIT_PER_GPU           = 1024
>>> GPU_FRACTION_LIMIT                 = .25
>>> NUM_PARALLEL_EXEC_UNITS            = 1
>>> NUM_PARALLEL_INTEROP               = 1
>>> print(tf.version.VERSION)
2.0.0
>>> model                              = tf.keras.models
>>> #ENABLE DEBUGGERING!
... tf.debugging.set_log_device_placement(True)
>>>
>>> config = tf.compat.v1.ConfigProto(device_count={"CPU": 0},
...             allow_soft_placement=True,
...             inter_op_parallelism_threads=NUM_PARALLEL_INTEROP,
...             intra_op_parallelism_threads=NUM_PARALLEL_EXEC_UNITS)
>>> gpus   = tf.config.experimental.list_physical_devices('GPU')
2019-12-02 02:18:53.487716: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll
2019-12-02 02:18:53.523698: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties:
name: GeForce GTX 1660 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.845
pciBusID: 0000:06:00.0
2019-12-02 02:18:53.540509: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.
2019-12-02 02:18:53.554359: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
>>> tf.config.experimental.set_visible_devices(gpus[GPU_DESIGNATION], 'GPU')
>>> config.gpu_options.per_process_gpu_memory_fraction = GPU_FRACTION_LIMIT
>>> tf.config.experimental.set_memory_growth(gpus[GPU_DESIGNATION], ALLOW_MEMORY_GROWTH)
>>> print(len(gpus),Fore.RED +  "Physical GPUs," + Style.RESET_ALL)
1 Physical GPUs,
>>>
>>> def gpu_compute_timed1(gpunum):
...     start = timer()
...     with tf.device(gpunum):
...         print(Fore.MAGENTA + Back.WHITE + "Loading Dataset!" + Style.RESET_ALL)
...         mnist = tf.keras.datasets.mnist
...         (x_train, y_train), (x_test, y_test) = mnist.load_data()
...         x_train, x_test = x_train / 255.0, x_test / 255.0
...     end = timer()
...     print(Fore.MAGENTA + str(end - start)  + Style.RESET_ALL)
...
>>> def gpu_compute_timed2(gpunum):
...     with tf.device(gpunum):
...         start = timer()
...         print(Fore.MAGENTA + Back.WHITE + "Loading Dataset!" + Style.RESET_ALL)
...         mnist = tf.keras.datasets.mnist
...         (x_train, y_train), (x_test, y_test) = mnist.load_data()
...         x_train, x_test = x_train / 255.0, x_test / 255.0
...         end = timer()
...         print(Fore.MAGENTA + str(end - start)  + Style.RESET_ALL)
...         print(Fore.MAGENTA + Back.WHITE + "Compiling Model!" + Style.RESET_ALL)
...         model = tf.keras.models.Sequential([
...             tf.keras.layers.Flatten(input_shape=(28, 28)),
...             tf.keras.layers.Dense(128, activation='relu'),
...             tf.keras.layers.Dropout(0.2),
...             tf.keras.layers.Dense(10, activation='softmax')
...             ])
...         model.compile(optimizer='adam',
...                         loss='sparse_categorical_crossentropy',
...                         metrics=['accuracy'])
...         end = timer()
...         print(Fore.MAGENTA + str(end - start)  + Style.RESET_ALL)
...         start = timer()
...         print(Fore.MAGENTA + Back.WHITE + "Fitting Model!" + Style.RESET_ALL)
...         model.fit(x_train, y_train, epochs=5)
...         end = timer()
...         print(Fore.MAGENTA + str(end - start)  + Style.RESET_ALL)
...         start = timer()
...         print(Fore.MAGENTA + Back.WHITE + "Evaluating Model!" + Style.RESET_ALL)
...         model.evaluate(x_test,  y_test, verbose=2)
...         end = timer()
...         print(Fore.MAGENTA + str(end - start)  + Style.RESET_ALL)
...     return model
...
>>> gpu_compute_timed1(GPU_NUM)
2019-12-02 02:19:13.576257: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2019-12-02 02:19:13.593389: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties:
name: GeForce GTX 1660 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.845
pciBusID: 0000:06:00.0
2019-12-02 02:19:13.610672: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.
2019-12-02 02:19:13.624357: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2019-12-02 02:19:14.302448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-12-02 02:19:14.313341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0
2019-12-02 02:19:14.321469: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N
2019-12-02 02:19:14.329624: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4630 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1660 SUPER, pci bus id: 0000:06:00.0, compute capability: 7.5)
Loading Dataset!
1.2370402
>>> asdf = gpu_compute_timed2(GPU_NUM)
Loading Dataset!
0.4652890000000003
Compiling Model!
0.7483474999999995
Fitting Model!
Train on 60000 samples
Epoch 1/5
2019-12-02 02:19:26.087287: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_100.dll
60000/60000 [==============================] - 9s 145us/sample - loss: 0.2924 - accuracy: 0.9143
Epoch 2/5
60000/60000 [==============================] - 4s 69us/sample - loss: 0.1443 - accuracy: 0.9570
Epoch 3/5
60000/60000 [==============================] - 4s 69us/sample - loss: 0.1072 - accuracy: 0.9679
Epoch 4/5
60000/60000 [==============================] - 4s 72us/sample - loss: 0.0890 - accuracy: 0.9728
Epoch 5/5
60000/60000 [==============================] - 4s 71us/sample - loss: 0.0746 - accuracy: 0.9762
2019-12-02 02:19:48.081067: I tensorflow/core/common_runtime/eager/execute.cc:574] Executing op DeleteIterator in device /job:localhost/replica:0/task:0/device:CPU:0
26.109568499999998
Evaluating Model!
0/device:GPU:0
10000/1 - 2s - loss: 0.0382 - accuracy: 0.9780
2.3329016000000067